# Решение задачи разделения рынка методами машинного обучения с подкреплением

## Описание проекта

Этот проект представляет выпускную квалификационную работу (ВКР) Хайрутдинова Эльмира Рамиловича на тему: **"Решение задачи разделения рынка методами машинного обучения с подкреплением."**

В рамках данной работы мы исследуем различные подходы к решению задачи разделения рынка, используя методы машинного обучения и обучения с подкреплением (RL). В проекте представлено несколько подходов, начиная с базового метода перебора и заканчивая продвинутыми методами обучения с подкреплением.

## Структура проекта

Проект состоит из следующих файлов:

- `bruteforce.py`: Реализация метода перебора для решения задачи.
- `dimension.py`: Реализация построения графика зависимости времени обучения от размерности задачи.
- `PPO.py`: Основная реализация метода обучения с подкреплением на основе Proximal Policy Optimization (PPO).

## О методе PPO

**Proximal Policy Optimization (PPO)** — это один из современных методов обучения с подкреплением, который используется для оптимизации политики агента. PPO сочетает в себе эффективность и простоту реализации, обеспечивая стабильность обучения благодаря использованию метода ограничения доверительного региона (Trust Region). Основные преимущества PPO:
